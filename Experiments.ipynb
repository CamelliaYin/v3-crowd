{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371326e-7384-46c8-83ca-d3f8139d6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78ae119-ffbb-442c-86f4-f4e086682b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=src\\yolov3.pt, cfg=, data=data/iid-tv.yaml, hyp=src\\data\\hyps\\hyp.scratch.yaml, epochs=15, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=src\\runs\\train, name=test1, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv3  2022-3-24 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir src\\runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/train/runs/qw4a9xe4\" target=\"_blank\">test1</a></strong> to <a href=\"https://wandb.ai/dddetection/train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to src\\yolov3.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86917e9c2c747feb40fa7fe951eff5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/119M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
      "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
      " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
      " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
      " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
      " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
      " 28      [27, 22, 15]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model Summary: 333 layers, 61529119 parameters, 61529119 gradients, 154.9 GFLOPs\n",
      "\n",
      "Transferred 433/439 items from src\\yolov3.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data\\datasets\\iid-tv\\labels\\train' images and labels...298 found, 22 missing, 0 empty, 0 corrupted: 100%|██████████| 320/320 [00:04<00:00, 70.44it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data\\datasets\\iid-tv\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data\\datasets\\iid-tv\\labels\\val' images and labels...20 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 20/20 [00:06<00:00,  3.00it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: data\\datasets\\iid-tv\\labels\\val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.04 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'signal' has no attribute 'SIGALRM'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1msrc\\runs\\train\\test1\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/14     14.1G    0.1144   0.04806   0.02895       113       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80     0.0055     0.0135   0.000921   0.000209\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/14       15G    0.1047   0.05127   0.02427        83       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80    0.00207     0.0251   0.000311   4.54e-05\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/14       15G   0.09897   0.05244   0.01951       103       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80     0.0143     0.0116    0.00257   0.000768\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/14       15G   0.09569   0.05536   0.01572       159       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80     0.0246      0.151     0.0242    0.00327\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/14       15G    0.0912   0.05067   0.01344       111       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.562     0.0349     0.0169    0.00321\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/14       15G   0.08509      0.05   0.01093       109       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.572      0.161      0.046     0.0105\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/14       15G   0.08146   0.04732  0.009458       102       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.635      0.138     0.0774     0.0155\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/14       15G   0.07881    0.0461   0.01004       144       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.564      0.128     0.0314     0.0052\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/14       15G   0.07567   0.04443  0.008358       143       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80       0.57      0.174     0.0392    0.00708\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/14       15G   0.07415   0.04621  0.008156        89       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.655      0.233      0.125     0.0237\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/14       15G   0.07324   0.04454  0.008296       117       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.577      0.151     0.0434    0.00588\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/14       15G   0.07171   0.04468  0.008405        97       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.615      0.232      0.105     0.0227\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/14       15G   0.06939   0.04476  0.007484       119       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.673      0.209      0.146     0.0254\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/14       15G   0.06985   0.04253  0.008076        93       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.598      0.244     0.0803     0.0153\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/14       15G   0.06944   0.04389  0.007115       132       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80       0.61      0.291      0.109      0.022\n",
      "\n",
      "15 epochs completed in 0.042 hours.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from src\\runs\\train\\test1\\weights\\last.pt, 123.6MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating src\\runs\\train\\test1\\weights\\best.pt...\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from src\\runs\\train\\test1\\weights\\best.pt, 123.6MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 261 layers, 61502815 parameters, 0 gradients, 154.7 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         20         80      0.668      0.209      0.145     0.0253\n",
      "           bone-loss         20         43      0.336      0.419      0.288     0.0502\n",
      "       dental-caries         20         37          1          0    0.00196   0.000392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7012... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 183.98MB of 185.49MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.9918814…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▁▁▂▂▃▅▂▃▇▃▆█▅▆</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▁▁▁▂▂▄▅▂▃█▃▇█▅▇</td></tr><tr><td>metrics/precision</td><td>▁▁▁▁▇▇█▇▇█▇▇█▇▇</td></tr><tr><td>metrics/recall</td><td>▁▁▁▅▂▅▄▄▅▇▅▇▆▇█</td></tr><tr><td>train/box_loss</td><td>█▇▆▅▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▇▅▄▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/obj_loss</td><td>▄▆▆█▅▅▄▃▂▃▂▂▂▁▂</td></tr><tr><td>val/box_loss</td><td>█▅▅▄▄▂▃▄▄▁▄▂▂▃▂</td></tr><tr><td>val/cls_loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▁▁▁</td></tr><tr><td>val/obj_loss</td><td>██▆▆▅▅▄▁▁▃▁▂▂▁▂</td></tr><tr><td>x/lr0</td><td>▁▃▄▆▇███▇▇▆▅▄▃▂</td></tr><tr><td>x/lr1</td><td>▁▃▄▆▇███▇▇▆▅▄▃▂</td></tr><tr><td>x/lr2</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>0.10945</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.02204</td></tr><tr><td>metrics/precision</td><td>0.6104</td></tr><tr><td>metrics/recall</td><td>0.2907</td></tr><tr><td>train/box_loss</td><td>0.06944</td></tr><tr><td>train/cls_loss</td><td>0.00712</td></tr><tr><td>train/obj_loss</td><td>0.04389</td></tr><tr><td>val/box_loss</td><td>0.08588</td></tr><tr><td>val/cls_loss</td><td>0.02358</td></tr><tr><td>val/obj_loss</td><td>0.03728</td></tr><tr><td>x/lr0</td><td>0.00026</td></tr><tr><td>x/lr1</td><td>0.00026</td></tr><tr><td>x/lr2</td><td>0.07636</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 491 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test1</strong>: <a href=\"https://wandb.ai/dddetection/train/runs/qw4a9xe4\" target=\"_blank\">https://wandb.ai/dddetection/train/runs/qw4a9xe4</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220324_134447-qw4a9xe4\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1msrc\\runs\\train\\test1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i src/train.py --data data/iid-tv.yaml --batch-size 20 --epochs 15 --name test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34df95c0-2be4-433e-a502-81eed8174842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=src\\yolov3.pt, cfg=, data=data/Calc_Removed_New_Test_50min_IID.yaml, hyp=src\\data\\hyps\\hyp.scratch.yaml, epochs=15, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=src\\runs\\train, name=test2, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv3  2022-3-24 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir src\\runs\\train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/train/runs/2rk3m3y5\" target=\"_blank\">test2</a></strong> to <a href=\"https://wandb.ai/dddetection/train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
      "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
      " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
      " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
      " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
      " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
      " 28      [27, 22, 15]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model Summary: 333 layers, 61529119 parameters, 61529119 gradients, 154.9 GFLOPs\n",
      "\n",
      "Transferred 433/439 items from src\\yolov3.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data\\datasets\\Calc_Removed_New_Test_50min_IID\\labels\\train.cache' images and labels... 5250 found, 0 missing, 0 empty, 3 corrupted: 100%|██████████| 5250/5250 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: data\\datasets\\Calc_Removed_New_Test_50min_IID\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.akshata.p.hegde.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0033]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: data\\datasets\\Calc_Removed_New_Test_50min_IID\\images\\train\\Unknown-X-20200504-172853-XMLH9GTN4NAM-0.Debreziner.JPG: ignoring corrupt image/label: negative label values [   -0.11728]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: data\\datasets\\Calc_Removed_New_Test_50min_IID\\images\\train\\Unknown-X-20201005-103909-XNCQOIKATKR9-0.chrispsimmons.JPG: ignoring corrupt image/label: negative label values [   -0.62384    -0.64215]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data\\datasets\\Calc_Removed_New_Test_50min_IID\\labels\\val.cache' images and labels... 669 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 669/669 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.42 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1msrc\\runs\\train\\test22\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'signal' has no attribute 'SIGALRM'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/14     14.1G   0.08809   0.04569   0.02169        24       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.636      0.217      0.112     0.0227\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/14     21.3G   0.07546    0.0457   0.01243        38       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.133      0.242      0.112     0.0211\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/14     21.3G   0.07119   0.04534  0.009942        38       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.191       0.22      0.132     0.0267\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/14     21.3G    0.0703   0.04541   0.00974        31       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.201      0.237      0.144     0.0304\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/14     21.3G   0.06912   0.04605  0.009429        28       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.235      0.303      0.182     0.0392\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/14     21.3G   0.06744   0.04529  0.008751        32       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.198      0.241      0.156     0.0351\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/14     21.3G   0.06642   0.04576   0.00851        29       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.205      0.261      0.153     0.0344\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/14     21.3G   0.06568    0.0455  0.007949        15       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.192      0.254      0.141      0.029\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/14     21.3G    0.0645   0.04584  0.007642        28       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.198      0.217      0.132     0.0286\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/14     21.3G   0.06374   0.04615  0.007246        41       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.207      0.215      0.138     0.0287\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/14     21.3G   0.06245   0.04586  0.006846        20       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.224      0.245      0.157     0.0356\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/14     21.3G   0.06191   0.04516  0.006607        34       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.206      0.217      0.129     0.0262\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/14     21.3G    0.0607   0.04541  0.006303        37       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.201      0.248      0.152     0.0315\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/14     21.3G   0.05974   0.04568  0.005803        29       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.211      0.247      0.149     0.0324\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/14     21.3G   0.05896   0.04519   0.00562        29       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.201      0.253      0.142     0.0309\n",
      "\n",
      "15 epochs completed in 0.471 hours.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from src\\runs\\train\\test22\\weights\\last.pt, 123.5MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating src\\runs\\train\\test22\\weights\\best.pt...\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from src\\runs\\train\\test22\\weights\\best.pt, 123.5MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 261 layers, 61502815 parameters, 0 gradients, 154.7 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        669       3316      0.238      0.298      0.182     0.0392\n",
      "           bone-loss        669       2097       0.36      0.468      0.307     0.0648\n",
      "       dental-caries        669       1219      0.115      0.128     0.0561     0.0137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29544... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 178.47MB of 180.31MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.9897844…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▁▃▄█▅▅▄▃▄▆▃▅▅▄</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▂▁▃▅█▆▆▄▄▄▇▃▅▅▅</td></tr><tr><td>metrics/precision</td><td>█▁▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>metrics/recall</td><td>▁▃▁▃█▃▅▄▁▁▃▁▄▄▄</td></tr><tr><td>train/box_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/obj_loss</td><td>▅▅▂▃▇▂▅▃▆█▆▁▃▅▁</td></tr><tr><td>val/box_loss</td><td>▄▆▅▆▁▄▄▅█▅▃▅▅▄▅</td></tr><tr><td>val/cls_loss</td><td>█▂▂▂▁▂▁▂▂▂▃▃▁▃▂</td></tr><tr><td>val/obj_loss</td><td>▆▂▃▁▄▇▅▃▁▄▆█▇█▇</td></tr><tr><td>x/lr0</td><td>▂▄▇██▇▇▆▅▄▃▃▂▁▁</td></tr><tr><td>x/lr1</td><td>▂▄▇██▇▇▆▅▄▃▃▂▁▁</td></tr><tr><td>x/lr2</td><td>█▆▄▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>0.14231</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.03089</td></tr><tr><td>metrics/precision</td><td>0.20069</td></tr><tr><td>metrics/recall</td><td>0.25269</td></tr><tr><td>train/box_loss</td><td>0.05896</td></tr><tr><td>train/cls_loss</td><td>0.00562</td></tr><tr><td>train/obj_loss</td><td>0.04519</td></tr><tr><td>val/box_loss</td><td>0.07403</td></tr><tr><td>val/cls_loss</td><td>0.00995</td></tr><tr><td>val/obj_loss</td><td>0.06361</td></tr><tr><td>x/lr0</td><td>0.00139</td></tr><tr><td>x/lr1</td><td>0.00139</td></tr><tr><td>x/lr2</td><td>0.00139</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 495 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test2</strong>: <a href=\"https://wandb.ai/dddetection/train/runs/2rk3m3y5\" target=\"_blank\">https://wandb.ai/dddetection/train/runs/2rk3m3y5</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220324_141355-2rk3m3y5\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1msrc\\runs\\train\\test22\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i src/train.py --data data/Calc_Removed_New_Test_50min_IID.yaml --batch-size 20 --epochs 15 --name test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e2706-7557-47e9-9442-e038a0aefec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

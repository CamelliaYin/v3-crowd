{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1e4e60",
   "metadata": {},
   "source": [
    "# construct bcc functionality within a .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c183fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as ss\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52d721e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input X\n",
    "# dummy volunteers answer for 4 volunteers, and 2 images\n",
    "\n",
    "vol_bg = np.zeros((2,25000,4))+2 #background agreed \n",
    "vol_entry = np.random.choice(3, (2, 200, 4)) #real labels \n",
    "vol_ans = np.concatenate((vol_entry, vol_bg), axis=1) # all 25200\n",
    "vol_ans = torch.from_numpy(vol_ans) # make tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b239d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input nn_ouput\n",
    "# dummy prediction from nn model for 2 images\n",
    "\n",
    "nn_pred = torch.rand(2,25200,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f25baed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_max_fun(t1, t2):\n",
    "    if not torch.is_tensor(t1):\n",
    "        t1 = torch.tensor(t1)\n",
    "    if not torch.is_tensor(t2):\n",
    "        t2 = torch.tensor(t2)\n",
    "    return torch.max(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a216d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_module_map = {'base_lib': torch,\n",
    "                    'gammaln': torch.special.gammaln, \n",
    "                    'digamma': torch.digamma,\n",
    "                    'simple_transpose': lambda x: torch.permute(x, tuple(range(x.ndim)[::-1])),\n",
    "                    'copy': lambda x: x.clone().detach(),\n",
    "                    'maxwithdim': lambda x, d: torch.max(x, d).values,\n",
    "                    'maximum': lambda t1, t2: torch_max_fun(t1, t2),\n",
    "                    'expand_dim': torch.unsqueeze\n",
    "                    }\n",
    "\n",
    "np_module_map = {'base_lib': np,\n",
    "                 'gammaln': ss.gammaln,\n",
    "                 'digamma': ss.psi,\n",
    "                 'simple_transpose': np.transpose,\n",
    "                 'copy': np.copy,\n",
    "                 'maxwithdim': np.max,\n",
    "                 'maximum': np.maximum,\n",
    "                 'expand_dim': np.expand_dims\n",
    "                 }\n",
    "\n",
    "def get_modules(torchMode=False, module_names=None):\n",
    "    module_names = module_names or ['base_lib']\n",
    "    module_map = torch_module_map if torchMode else np_module_map\n",
    "    modules = [module_map[x] for x in module_names]\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03e518a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logB_from_Dirichlet_parameters(alpha, torchMode=False):\n",
    "    base_lib, gammaln_fn = get_modules(torchMode, ['base_lib', 'gammaln'])\n",
    "    logB = base_lib.sum(gammaln_fn(alpha)) - gammaln_fn(base_lib.sum(alpha))\n",
    "    return logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55e25933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_log_Dirichlet_parameters(param, torchMode=False, device=None):\n",
    "    base_lib, digamma_fn, simple_transpose = get_modules(torchMode, ['base_lib', 'digamma', 'simple_transpose'])        \n",
    "    size = param.shape\n",
    "    result = base_lib.zeros_like(param)\n",
    "    if torchMode:\n",
    "        result = result.to(device)\n",
    "\n",
    "    if len(size) == 1:\n",
    "        result = digamma_fn(param) - digamma_fn(base_lib.sum(param))\n",
    "    elif len(size) == 2:  # when we take A_0 for everyone\n",
    "        result = digamma_fn(param) - simple_transpose(base_lib.tile(digamma_fn(base_lib.sum(param, 1)), (size[1], 1)))\n",
    "    elif len(size) == 3:  # most of time for posterior cm\n",
    "        for i in range(size[2]):\n",
    "            result[:, :, i] = digamma_fn(param[:, :, i]) - \\\n",
    "                              simple_transpose(base_lib.tile(digamma_fn(base_lib.sum(param[:, :, i], 1)), (size[1], 1)))\n",
    "    else:\n",
    "        raise Exception('param can have no more than 3 dimensions')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01f8789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_true_labels(X, nn_output, ElogPi_volunteer, torchMode=False, device=None):\n",
    "    base_lib, copy_fn, simple_transpose, maxwithdim_fn, maximum_fn = get_modules(torchMode, ['base_lib', 'copy', 'simple_transpose', 'maxwithdim', 'maximum'])\n",
    "    I, U, K = X.shape  # I = no. of image, U = no. of anc hor boxes in total, K = no. of volunteers\n",
    "    M = ElogPi_volunteer.shape[0]  # M = Number of classes\n",
    "    N = ElogPi_volunteer.shape[1]  # N = Number of classes used by volunteers\n",
    "    rho = copy_fn(nn_output)  # I x U x M logits\n",
    "    # eq. 12:\n",
    "    # loops for the number of volunteers\n",
    "    for k in range(K):\n",
    "        inds = tuple([x.long() for x in base_lib.where(X[:, :, k] > -1)])  # rule out missing values\n",
    "        rho[inds[0], inds[1], :] += simple_transpose(ElogPi_volunteer[:, base_lib.squeeze(X[inds[0], inds[1], k]).long(), k])\n",
    "\n",
    "\n",
    "    # normalisation: (minus the max of each anchor)\n",
    "    rho -= simple_transpose(base_lib.tile(simple_transpose(maxwithdim_fn(rho, 2)), (M, 1, 1)))\n",
    "\n",
    "    # # eq. 11:\n",
    "    q_t = base_lib.exp(rho) / maximum_fn(1e-60, simple_transpose(base_lib.tile(simple_transpose(base_lib.sum(base_lib.exp(rho), 2)), (M, 1, 1))))\n",
    "    q_t = maximum_fn(1e-60, q_t)\n",
    "\n",
    "    # partial of eq. 8: (right side 2nd term)\n",
    "    f_iu = base_lib.zeros((M, N, K), dtype=base_lib.float64)\n",
    "    if torchMode:\n",
    "        f_iu = f_iu.to(device)\n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            ids0 = base_lib.where(X[:, :, k] == n)[0]\n",
    "            ids1 = base_lib.where(X[:, :, k] == n)[1]\n",
    "            f_iu[:, n, k] = base_lib.sum(q_t[ids0, ids1, :], 0)\n",
    "#     rho.shape, rho\n",
    "    return q_t, f_iu, rho #(I x U x M), (M x N x K), (I x U x M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "126131e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_volunteers(alpha0_volunteers, f_iu, torchMode=False, device=None):\n",
    "    (base_lib,) = get_modules(torchMode, ['base_lib'])\n",
    "    K = alpha0_volunteers.shape[2]\n",
    "    alpha_volunteers = base_lib.zeros_like(alpha0_volunteers)\n",
    "    if torchMode:\n",
    "        alpha_volunteers = alpha_volunteers.to(device)\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    for k in range(K):\n",
    "        alpha_volunteers[:, :, k] = alpha0_volunteers[:, :, k] + f_iu[:, :, k]\n",
    "\n",
    "    return alpha_volunteers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3a1f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from govind\n",
    "def compute_lower_bound_likelihood(alpha0_volunteers, alpha_volunteers, q_t, rho, nn_output, torchMode=False):\n",
    "    (base_lib,) = get_modules(torchMode, ['base_lib'])\n",
    "    \n",
    "    W = alpha0_volunteers.shape[2]\n",
    "\n",
    "    ll_pi_worker = 0\n",
    "    for w in range(W):\n",
    "        ll_pi_worker -= base_lib.sum(logB_from_Dirichlet_parameters(alpha0_volunteers[:, :, w], torchMode=torchMode) -\n",
    "                                             logB_from_Dirichlet_parameters(alpha_volunteers[:, :, w], torchMode=torchMode))\n",
    "\n",
    "    ll_t = -base_lib.sum(q_t * rho) + base_lib.sum(base_lib.log(base_lib.sum(base_lib.exp(rho), axis=1)), axis=0)\n",
    "\n",
    "    ll_nn = base_lib.sum(q_t * nn_output) - base_lib.sum(base_lib.log(base_lib.sum(base_lib.exp(nn_output), axis=1)), axis=0)\n",
    "    \n",
    "    ll = ll_pi_worker + ll_t + ll_nn  # VB lower bound\n",
    "\n",
    "    return base_lib.sum(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb70ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my old version\n",
    "def compute_lower_bound_likelihood_check(alpha0_volunteers, alpha_volunteers, q_t, rho, nn_output, torchMode=False):\n",
    "    (base_lib,) = get_modules(torchMode, ['base_lib'])\n",
    "    \n",
    "    W = alpha0_volunteers.shape[2]\n",
    "\n",
    "    ll_pi_worker = 0\n",
    "    for w in range(W):\n",
    "        ll_pi_worker -= base_lib.sum(logB_from_Dirichlet_parameters(alpha0_volunteers[:, :, w], torchMode=torchMode) -\n",
    "                                             logB_from_Dirichlet_parameters(alpha_volunteers[:, :, w], torchMode=torchMode))\n",
    "\n",
    "    ll_t = -base_lib.sum(q_t * rho) + base_lib.sum(base_lib.log(base_lib.sum(base_lib.exp(rho), axis=2)))\n",
    "\n",
    "    ll_nn = base_lib.sum(q_t * nn_output) - base_lib.sum(base_lib.log(base_lib.sum(base_lib.exp(nn_output), axis=2)))\n",
    "    \n",
    "    ll = ll_pi_worker + ll_t + ll_nn  # VB lower bound\n",
    "\n",
    "    return base_lib.sum(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec4e0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_prior(n_classes, n_volunteers, alpha_diag_prior, torchMode=False):\n",
    "    \"\"\"\n",
    "    Create confusion matrix prior for every volunteer - the same prior for each volunteer\n",
    "    :param n_classes: number of classes (int)\n",
    "    :param n_volunteers: number of crowd members (int)\n",
    "    :param alpha_diag_prior: prior for confusion matrices is assuming reasonable crowd members with weak dominance of a\n",
    "    diagonal elements of confusion matrices, i.e. prior for a confusion matrix is a matrix of all ones where\n",
    "    alpha_diag_prior is added to diagonal elements (float)\n",
    "    :return: numpy nd-array of the size (n_classes, n_classes, n_volunteers)\n",
    "    \"\"\"\n",
    "    base_lib = torch if torchMode else np\n",
    "    alpha_volunteer_template = base_lib.ones((n_classes, n_classes), dtype=base_lib.float64) + alpha_diag_prior * base_lib.eye(n_classes)\n",
    "    if base_lib == torch:\n",
    "        return base_lib.tile(base_lib.unsqueeze(alpha_volunteer_template, axis=2), (1, 1, n_volunteers))\n",
    "    else:\n",
    "        return base_lib.tile(base_lib.expand_dims(alpha_volunteer_template, axis=2), (1, 1, n_volunteers))\n",
    "\n",
    "# if take alpha_diag_prior = 0.1 (Olga's experiment setting)\n",
    "## sim_prior = initialise_prior(3,2,0.1)\n",
    "## print(sim_prior[:,:,1]) == print(sim_prior[:,:,1])\n",
    "## [[1.1 1.  1. ]\n",
    "## [1.  1.1 1. ]\n",
    "## [1.  1.  1.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57c2c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_param_confusion_matrices(bcc_params, torchMode=False):\n",
    "    # set up variational parameters\n",
    "    prior_param_confusion_matrices = initialise_prior(n_classes=bcc_params['n_classes'],\n",
    "                                                   n_volunteers=bcc_params['n_crowd_members'],\n",
    "                                               alpha_diag_prior=bcc_params['confusion_matrix_diagonal_prior'],\n",
    "                                                   torchMode = torchMode)\n",
    "    variational_param_confusion_matrices = prior_param_confusion_matrices.detach().clone() if torchMode else np.copy(prior_param_confusion_matrices)\n",
    "    return {'prior': prior_param_confusion_matrices, 'variational': variational_param_confusion_matrices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2dc1f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check inside of VB:\n",
    "alpha0 = initialise_prior(3,4,0.1, torchMode=True)\n",
    "alpha = alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "17bd63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  VB_iteration(X, nn_output, alpha_volunteers, alpha0_volunteers, torchMode=False, device=None):\n",
    "    \"\"\"\n",
    "    performs one iteration of variational inference update for BCCNet (E-step)\n",
    "    -- update for approximating posterior of true labels and confusion matrices\n",
    "    I - number of data points\n",
    "    M - number of true classes\n",
    "    N - number of classes used by volunteers (normally M == N)\n",
    "    K - number of volunteers (W)\n",
    "    :param X: I X U X V X K volunteers answers, for image i, the grid choice u, the vth anchor box, the kth volunteer,\n",
    "              -1 encodes a missing answer (where the volunteer can not identify abnormality there.)\n",
    "    :param nn_output: (I x U X V) x M logits (not a softmax output!) note here the nn_output is only the partial output\n",
    "                      from the object detection NN.\n",
    "    :param alpha_volunteers: M X N X K - current parameters of posterior Dirichlet for confusion matrices\n",
    "    :param alpha0_volunteers: M X N -  parameters of the prior Dirichlet for confusion matrix\n",
    "    :return: q_t - approximating posterior for true labels, alpha_volunteers - updated posterior for confusion matrices,\n",
    "        lower_bound_likelihood - ELBO\n",
    "    \"\"\"\n",
    "    # torchMode = all([torch.is_tensor(x) for x in [X, nn_output, alpha_volunteers, alpha0_volunteers]])\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    ElogPi_volunteer = expected_log_Dirichlet_parameters(alpha_volunteers, torchMode, device=device)\n",
    "\n",
    "    # q_t\n",
    "    #print('X: ', X, 'nn_output: ', nn_output, 'ElogPi_volunteer: ', ElogPi_volunteer, 'torchMode: ', torchMode)\n",
    "    q_t, Njl, rho = expected_true_labels(X, nn_output, ElogPi_volunteer, torchMode, device=device)\n",
    "\n",
    "    # q_pi_workers\n",
    "    alpha_volunteers = update_alpha_volunteers(alpha0_volunteers, Njl, torchMode, device=device)\n",
    "\n",
    "    # Low bound\n",
    "    lower_bound_likelihood = compute_lower_bound_likelihood(alpha0_volunteers, alpha_volunteers, q_t, rho, nn_output, torchMode)\n",
    "\n",
    "    return q_t, alpha_volunteers, lower_bound_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62dea25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_t, alpha_volunteers, lower_bound_likelihood = VB_iteration(vol_ans, nn_pred, alpha, alpha0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ede16f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-534312.8750)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15c7171a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 4])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Njl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3fdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
